// /app/api/transcribe/route.ts

import { NextRequest, NextResponse } from "next/server";
import { createClient as createServiceRoleClient } from "@supabase/supabase-js";
import Anthropic from "@anthropic-ai/sdk";
// Deepgram SDK ì„í¬íŠ¸ ì œê±°

export const maxDuration = 300;

const supabaseAdmin = createServiceRoleClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
);

const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY!,
});

// Deepgram API URL ì§ì ‘ ì •ì˜
const DEEPGRAM_API_URL = "https://api.deepgram.com/v1/listen?model=nova-2&language=ko&smart_format=true&diarize=true";

// --- í—¬í¼ í•¨ìˆ˜ 1: STT (Deepgram - fetch ì‚¬ìš©) ---
async function transcribeAudio(audioFile: File): Promise<string | null> {
  console.log(`[AI Pipeline] Using Deepgram API (fetch) for file: ${audioFile.name}`);

  const audioBuffer = await audioFile.arrayBuffer();

  // 1. (í•µì‹¬ ìˆ˜ì •) íŒŒì¼ í™•ì¥ìë¥¼ ê¸°ë°˜ìœ¼ë¡œ MIME Typeì„ ì§ì ‘ ê²°ì •í•©ë‹ˆë‹¤.
  //    File.typeì´ ê°€ë” ë¶€ì •í™•í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì—, í™•ì¥ìê°€ ë” í™•ì‹¤í•©ë‹ˆë‹¤.
  let mimeType = audioFile.type;
  const ext = audioFile.name.split(".").pop()?.toLowerCase();

  if (ext === "mp3") mimeType = "audio/mpeg";
  else if (ext === "wav") mimeType = "audio/wav";
  else if (ext === "m4a") mimeType = "audio/mp4";
  else if (ext === "webm") mimeType = "audio/webm";

  // ë§Œì•½ ì—¬ì „íˆ íƒ€ì…ì´ ì—†ë‹¤ë©´ Deepgramì´ ì•Œì•„ì„œ í•˜ë„ë¡ í—¤ë”ë¥¼ ìƒëµí•˜ê±°ë‚˜ ì¼ë°˜ íƒ€ì… ì‚¬ìš©
  if (!mimeType) mimeType = "audio/*";

  console.log(`[AI Pipeline] Determining MIME type for Deepgram: ${mimeType}`);

  const response = await fetch(DEEPGRAM_API_URL, {
    method: "POST",
    headers: {
      Authorization: `Token ${process.env.DEEPGRAM_API_KEY!}`,
      "Content-Type": mimeType, // ê²°ì •ëœ MIME Type ì‚¬ìš©
    },
    body: audioBuffer,
  });

  if (!response.ok) {
    const errorBody = await response.json();
    throw new Error(`Deepgram STT Error: ${errorBody.err_msg || errorBody.reason || "Unknown error"}`);
  }

  const result = await response.json();
  const transcript = result.results?.channels[0]?.alternatives[0]?.transcript;

  if (!transcript || transcript.trim().length === 0) {
    console.log("[AI Pipeline] No speech detected.");
    return null;
  }

  console.log("[AI Pipeline] Deepgram STT Complete.");
  return transcript;
}

// --- í—¬í¼ í•¨ìˆ˜ 2: LLM (ì–‘ì‹ ì±„ìš°ê¸° - Claude) ---
async function analyzeTranscript(assessmentId: string, transcript: string): Promise<void> {
  const { data: assessmentData, error: fetchError } = await supabaseAdmin
    .from("assessments")
    .select(
      `
      id,
      assessment_templates (
        template_name,
        template_items (id, header_name, sort_order, parent_id)
      ),
      findings (id, photo_before_url, timestamp_seconds)
    `
    )
    .eq("id", assessmentId)
    .single();

  if (fetchError) throw new Error(`DB ì¡°íšŒ ì‹¤íŒ¨: ${fetchError.message}`);

  const templateItems = (assessmentData.assessment_templates.template_items || []).sort(
    (a: any, b: any) => (a.sort_order || 0) - (b.sort_order || 0)
  );
  const findings = assessmentData.findings || [];

  const prompt = `
    ë‹¹ì‹ ì€ ë² í…Œë‘ ì•ˆì „ ì»¨ì„¤í„´íŠ¸ì˜ AI ë¹„ì„œì…ë‹ˆë‹¤.
    [í˜„ì¥ ë…¹ìŒ ëŒ€ë³¸]:
    ---
    ${transcript}
    ---
    [í‰ê°€ ì–‘ì‹]:
    ${JSON.stringify(
      templateItems.map((item) => ({ id: item.id, header: item.header_name, parent_id: item.parent_id })),
      null,
      2
    )}
    [ì‚¬ì§„ ëª©ë¡]:
    ${JSON.stringify(
      findings.map((f) => ({ id: f.id, timestamp: f.timestamp_seconds })),
      null,
      2
    )}

    [ì§€ì‹œ ì‚¬í•­]:
    ëŒ€ë³¸ì„ ì½ê³  ì–‘ì‹ì˜ ë¹ˆì¹¸ì„ ì±„ìš°ì„¸ìš”. í—¤ë”ë¥¼ ì§ì ‘ ë§í•˜ì§€ ì•Šì•„ë„ ë§¥ë½ì„ ì¶”ë¡ í•˜ì—¬ ì±„ì›Œì•¼ í•©ë‹ˆë‹¤.
    ëŒ€ë³¸ì—ì„œ ì—¬ëŸ¬ ìœ„í—˜ ìš”ì¸ ì„¸íŠ¸ë¥¼ ë°œê²¬í•˜ë©´ ê°ê° ë³„ë„ë¡œ ìƒì„±í•˜ì„¸ìš”.
    ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ nullë¡œ ë‘ì„¸ìš”.

    [ì¶œë ¥ í˜•ì‹]:
    ë°˜ë“œì‹œ [JSON_START]ì™€ [JSON_END] ì‚¬ì´ì— JSON ë°°ì—´ë§Œ ë„£ìœ¼ì„¸ìš”.
    [JSON_START]
    [
      { 
        "set_id": 1,
        "results": [
          { "template_item_id": "...", "result_value": "..." }
        ]
      }
    ]
    [JSON_END]
  `;

  const msg = await anthropic.messages.create({
    model: "claude-sonnet-4-5-20250929",
    max_tokens: 4096,
    messages: [{ role: "user", content: prompt }],
  });

  const responseText = msg.content[0].text;
  const jsonMatch = responseText.match(/\[JSON_START\]([\s\S]*?)\[JSON_END\]/);

  let jsonString: string;
  if (jsonMatch && jsonMatch[1]) {
    jsonString = jsonMatch[1].trim();
  } else {
    const start = responseText.indexOf("[");
    const end = responseText.lastIndexOf("]");
    if (start !== -1 && end !== -1 && end > start) {
      jsonString = responseText.substring(start, end + 1);
    } else {
      throw new Error("AI ì‘ë‹µì—ì„œ JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
    }
  }

  const resultsSets = JSON.parse(jsonString);
  const resultsToInsert: any[] = [];

  if (Array.isArray(resultsSets)) {
    resultsSets.forEach((set: any) => {
      if (Array.isArray(set.results)) {
        set.results.forEach((result: any) => {
          resultsToInsert.push({
            assessment_id: assessmentId,
            template_item_id: result.template_item_id,
            result_value: result.result_value,
          });
        });
      }
    });
  }

  if (resultsToInsert.length > 0) {
    const { error: insertError } = await supabaseAdmin.from("assessment_results").insert(resultsToInsert);
    if (insertError) throw new Error(`ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: ${insertError.message}`);
  }

  console.log(`[AI Pipeline] LLM Complete. ${resultsToInsert.length} answers saved.`);
}

// --- ë©”ì¸ POST í•¸ë“¤ëŸ¬ ---
export async function POST(req: NextRequest) {
  let assessmentId: string | null = null;

  try {
    const formData = await req.formData();
    const audioFile = formData.get("audioFile") as File | null;
    assessmentId = formData.get("assessmentId") as string | null;

    if (!audioFile || !assessmentId) {
      return NextResponse.json({ error: "Audio, Assessment ID required" }, { status: 400 });
    }

    // 1. STT (Deepgram fetch)
    const transcript = await transcribeAudio(audioFile);

    if (transcript === null) {
      await supabaseAdmin
        .from("assessments")
        .update({ status: "failed", error_message: "ìŒì„± ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤." })
        .eq("id", assessmentId);
      return NextResponse.json({ message: "No speech detected" });
    }

    await supabaseAdmin
      .from("assessments")
      .update({ transcript: transcript, status: "analyzing" })
      .eq("id", assessmentId);

    // 2. LLM (Claude)
    await analyzeTranscript(assessmentId, transcript);

    // 3. ì™„ë£Œ
    await supabaseAdmin.from("assessments").update({ status: "completed", error_message: null }).eq("id", assessmentId);

    return NextResponse.json({ message: "Analysis complete" });
  } catch (error: any) {
    console.error("ğŸ”¥ğŸ”¥ğŸ”¥ Pipeline Error:", error.message);
    if (assessmentId) {
      try {
        await supabaseAdmin
          .from("assessments")
          .update({ status: "failed", error_message: error.message })
          .eq("id", assessmentId);
      } catch (e) {}
    }
    return NextResponse.json({ error: error.message }, { status: 500 });
  }
}
